{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "CSV_PATH = \"AWCustomers.csv\"\n",
        "PAIR_IDX = (0, 1)\n",
        "\n",
        "df_raw = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "\n",
        "drop_if_present = [\n",
        "    'CustomerID','Title','FirstName','MiddleName','LastName','Suffix',\n",
        "    'AddressLine1','AddressLine2','City','StateProvinceName','StateProvince',\n",
        "    'CountryRegionName','CountryRegion','PostalCode','PhoneNumber','EmailAddress',\n",
        "    'BirthDate','DateFirstPurchase','CompanyName','GeographyKey','RegionKey',\n",
        "    'MaritalStatusLabel','GenderLabel','EducationLevelLabel','OccupationLabel'\n",
        "]\n",
        "\n",
        "candidate_features = [\n",
        "    'Age','YearlyIncome','AveMonthSpend','NumberCarsOwned','TotalChildren',\n",
        "    'NumberChildrenAtHome','Gender','MaritalStatus','HomeOwnerFlag','HouseOwnerFlag',\n",
        "    'Occupation','EnglishOccupation','Education','EnglishEducation','Region',\n",
        "    'CommuteDistance','BikeBuyer'\n",
        "]\n",
        "\n",
        "present_candidates = [c for c in candidate_features if c in df_raw.columns]\n",
        "df = df_raw.drop(columns=[c for c in drop_if_present if c in df_raw.columns], errors='ignore')\n",
        "if present_candidates:\n",
        "    df = df[[c for c in present_candidates if c in df.columns]]\n",
        "\n",
        "target_col = 'BikeBuyer' if 'BikeBuyer' in df.columns else None\n",
        "if target_col is not None:\n",
        "    y = df[target_col].copy()\n",
        "    X = df.drop(columns=[target_col])\n",
        "else:\n",
        "    y = None\n",
        "    X = df.copy()\n",
        "\n",
        "numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
        "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "X_num = pd.DataFrame(num_imputer.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index) if numeric_cols else pd.DataFrame(index=X.index)\n",
        "X_cat = pd.DataFrame(cat_imputer.fit_transform(X[categorical_cols]), columns=categorical_cols, index=X.index) if categorical_cols else pd.DataFrame(index=X.index)\n",
        "X_imputed = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "if numeric_cols:\n",
        "    X_num_minmax = pd.DataFrame(minmax_scaler.fit_transform(X_imputed[numeric_cols]), columns=[f\"{c}__minmax\" for c in numeric_cols], index=X.index)\n",
        "    X_num_std = pd.DataFrame(std_scaler.fit_transform(X_imputed[numeric_cols]), columns=[f\"{c}__std\" for c in numeric_cols], index=X.index)\n",
        "else:\n",
        "    X_num_minmax = pd.DataFrame(index=X.index)\n",
        "    X_num_std = pd.DataFrame(index=X.index)\n",
        "\n",
        "X_disc = pd.DataFrame(index=X.index)\n",
        "\n",
        "def safe_qcut(s, q=4, labels=None):\n",
        "    try:\n",
        "        return pd.qcut(s, q=q, duplicates='drop', labels=labels)\n",
        "    except Exception:\n",
        "        bins = np.linspace(s.min(), s.max(), num=min(q, len(np.unique(s))) + 1)\n",
        "        bins = np.unique(bins)\n",
        "        if len(bins) > 1:\n",
        "            return pd.cut(s, bins=bins, labels=labels[:len(bins)-1] if labels else None, include_lowest=True)\n",
        "        else:\n",
        "            return pd.Series(['bin_0'] * len(s), index=s.index)\n",
        "\n",
        "if 'Age' in numeric_cols:\n",
        "    X_disc['Age_bin'] = safe_qcut(X_imputed['Age'], q=4, labels=['Q1','Q2','Q3','Q4'])\n",
        "\n",
        "if 'YearlyIncome' in numeric_cols:\n",
        "    X_disc['YearlyIncome_bin'] = safe_qcut(X_imputed['YearlyIncome'], q=5, labels=['P20','P40','P60','P80','P100'])\n",
        "\n",
        "if 'CommuteDistance' in numeric_cols:\n",
        "    X_disc['CommuteDistance_bin'] = pd.cut(X_imputed['CommuteDistance'], bins=5, labels=['B1','B2','B3','B4','B5'], include_lowest=True)\n",
        "\n",
        "categoricals_to_encode = categorical_cols + [c for c in X_disc.columns if c.endswith('_bin')]\n",
        "if categoricals_to_encode:\n",
        "    def cap_rare_levels(series, min_count=20):\n",
        "        vc = series.value_counts(dropna=False)\n",
        "        rare = vc[vc < min_count].index\n",
        "        return series.where(~series.isin(rare), other='Other')\n",
        "\n",
        "    X_cat_for_ohe = X_imputed[categorical_cols].copy() if categorical_cols else pd.DataFrame(index=X.index)\n",
        "    for c in X_cat_for_ohe.columns:\n",
        "        X_cat_for_ohe[c] = cap_rare_levels(X_cat_for_ohe[c])\n",
        "\n",
        "    X_disc_for_ohe = X_disc.copy()\n",
        "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    X_ohe = pd.DataFrame(\n",
        "        ohe.fit_transform(pd.concat([X_cat_for_ohe, X_disc_for_ohe], axis=1)),\n",
        "        columns=ohe.get_feature_names_out(list(X_cat_for_ohe.columns) + list(X_disc_for_ohe.columns)),\n",
        "        index=X.index\n",
        "    )\n",
        "else:\n",
        "    X_ohe = pd.DataFrame(index=X.index)\n",
        "\n",
        "X_minmax_plus_cat = pd.concat([X_num_minmax, X_imputed[categorical_cols]], axis=1)\n",
        "X_std_plus_ohe = pd.concat([X_num_std, X_ohe], axis=1)\n",
        "\n",
        "X_sim = X_std_plus_ohe.dropna(axis=0, how='any')\n",
        "i, j = PAIR_IDX\n",
        "if j >= len(X_sim) or i >= len(X_sim):\n",
        "    i, j = 0, 1\n",
        "\n",
        "row_i = X_sim.iloc[[i]].to_numpy()\n",
        "row_j = X_sim.iloc[[j]].to_numpy()\n",
        "\n",
        "cos_sim = float(cosine_similarity(row_i, row_j)[0,0])\n",
        "\n",
        "X_bin = X_std_plus_ohe.copy()\n",
        "for c in X_num_std.columns:\n",
        "    X_bin[c] = (X_bin[c] > 0).astype(int)\n",
        "\n",
        "bi = X_bin.iloc[i].to_numpy().astype(int)\n",
        "bj = X_bin.iloc[j].to_numpy().astype(int)\n",
        "\n",
        "matches = np.sum(bi == bj)\n",
        "smc = matches / bi.size\n",
        "intersection = np.sum((bi == 1) & (bj == 1))\n",
        "union = np.sum((bi == 1) | (bj == 1))\n",
        "jaccard = (intersection / union) if union != 0 else 0.0\n",
        "\n",
        "print(f\"Simple Matching Coefficient (SMC): {smc:.4f}\")\n",
        "print(f\"Jaccard Similarity: {jaccard:.4f}\")\n",
        "print(f\"Cosine Similarity: {cos_sim:.4f}\")\n",
        "\n",
        "def map_commute_distance_to_miles(series):\n",
        "    mapping = {\n",
        "        '0-1 Miles': 0.5,'1-2 Miles': 1.5,'2-5 Miles': 3.5,'5-10 Miles': 7.5,'10+ Miles': 15.0,\n",
        "        '0-5 Miles': 2.5,'1-5 Miles': 3.0\n",
        "    }\n",
        "    if pd.api.types.is_numeric_dtype(series):\n",
        "        return series.astype(float)\n",
        "    else:\n",
        "        s = series.astype(str).str.strip()\n",
        "        out = s.map(mapping)\n",
        "        mask_na = out.isna()\n",
        "        if mask_na.any():\n",
        "            tmp = s[mask_na].str.replace(' Miles','', regex=False).str.replace('mile','', regex=False)\n",
        "            parsed = []\n",
        "            for val in tmp:\n",
        "                val = val.replace('+','')\n",
        "                if '-' in val:\n",
        "                    try:\n",
        "                        a,b = val.split('-')\n",
        "                        parsed.append((float(a)+float(b))/2.0)\n",
        "                    except:\n",
        "                        parsed.append(np.nan)\n",
        "                else:\n",
        "                    try:\n",
        "                        parsed.append(float(val))\n",
        "                    except:\n",
        "                        parsed.append(np.nan)\n",
        "            out.loc[mask_na] = parsed\n",
        "        return pd.to_numeric(out, errors='coerce')\n",
        "\n",
        "commute_col = None\n",
        "for c in df.columns:\n",
        "    if \"Commute\" in c or \"Distance\" in c:\n",
        "        commute_col = c\n",
        "        break\n",
        "\n",
        "income_col = None\n",
        "for c in df.columns:\n",
        "    if \"Income\" in c:\n",
        "        income_col = c\n",
        "        break\n",
        "\n",
        "if commute_col and income_col:\n",
        "    commute_series = X_imputed[commute_col] if commute_col in X_imputed.columns else df[commute_col]\n",
        "    income_series = X_imputed[income_col] if income_col in X_imputed.columns else df[income_col]\n",
        "\n",
        "    commute_numeric = map_commute_distance_to_miles(commute_series)\n",
        "    income_numeric = pd.to_numeric(income_series, errors='coerce')\n",
        "\n",
        "    corr_df = pd.DataFrame({'CommuteMiles': commute_numeric, 'YearlyIncome': income_numeric}).dropna()\n",
        "    if len(corr_df) >= 2:\n",
        "        pearson_corr = corr_df['CommuteMiles'].corr(corr_df['YearlyIncome'], method='pearson')\n",
        "        spearman_corr = corr_df['CommuteMiles'].corr(corr_df['YearlyIncome'], method='spearman')\n",
        "        print(f\"Pearson correlation: {pearson_corr:.4f}\")\n",
        "        print(f\"Spearman correlation: {spearman_corr:.4f}\")\n",
        "    else:\n",
        "        print(\"Not enough valid rows to compute correlation.\")\n",
        "else:\n",
        "    print(\"Commute distance column not found in dataset. Correlation cannot be computed.\")\n",
        "\n",
        "X_minmax_plus_cat.to_csv(\"processed_minmax_plus_cat.csv\", index=False)\n",
        "X_std_plus_ohe.to_csv(\"processed_std_plus_ohe.csv\", index=False)\n",
        "if target_col is not None:\n",
        "    y.to_csv(\"target_BikeBuyer.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HCQHut2iD28",
        "outputId": "bd6f5003-a39d-4017-bd84-8ba500cd0e9a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Matching Coefficient (SMC): 0.8750\n",
            "Jaccard Similarity: 0.7273\n",
            "Cosine Similarity: 0.6065\n",
            "Commute distance column not found in dataset. Correlation cannot be computed.\n"
          ]
        }
      ]
    }
  ]
}